{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "from skimage.feature import hog, greycomatrix, greycoprops\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.morphology import erosion, dilation, opening, closing, white_tophat\n",
    "import cv2\n",
    "from osgeo import gdal\n",
    "from osgeo import osr\n",
    "import numpy as np\n",
    "\n",
    "MAX_SCALE = 150\n",
    "\n",
    "def write_geotiff(out_file, in_arr, geotran, srs_wkt):\n",
    "    \"\"\"\n",
    "    in_arr must be in channels, rows, cols\n",
    "    \"\"\"\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    if len(in_arr.shape) == 3:\n",
    "        out = driver.Create(out_file, in_arr.shape[2], in_arr.shape[1], in_arr.shape[0], gdal.GDT_Float64)\n",
    "        out.SetGeoTransform(geotran) # the origin is the upper left of the input shapefile\n",
    "        for b in range(in_arr.shape[0]):\n",
    "            outband = out.GetRasterBand(b+1)\n",
    "            outband.WriteArray(in_arr[b])\n",
    "            outband.FlushCache()\n",
    "    else:\n",
    "        out = driver.Create(out_file, in_arr.shape[1], in_arr.shape[0], 1, gdal.GDT_Float64)\n",
    "        out.SetGeoTransform(geotran) # the origin is the upper left of the input shapefile\n",
    "        outband = out.GetRasterBand(1)\n",
    "        outband.WriteArray(in_arr)\n",
    "        outband.FlushCache()\n",
    "    out.SetProjection(srs_wkt)\n",
    "\n",
    "\n",
    "def hog_feature(image_name, block, scale, output=None, stat=None):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    ----------\n",
    "    image_name: str\n",
    "    block: int\n",
    "    scale: int\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    out_image: 3D ndarray\n",
    "    \"\"\"\n",
    "    ds = gdal.Open(image_name)\n",
    "    image = ds.ReadAsArray()\n",
    "    geotran = ds.GetGeoTransform()\n",
    "    ulx = geotran[0]\n",
    "    uly = geotran[3]\n",
    "    cell_width = geotran[1]\n",
    "    cell_height = geotran[5]\n",
    "    \n",
    "    out_srs = osr.SpatialReference()\n",
    "    out_srs.ImportFromEPSG(4326)\n",
    "    out_srs_wkt = out_srs.ExportToWkt()\n",
    "    out_cell_width = block * cell_width\n",
    "    out_cell_height = block * cell_height\n",
    "    \n",
    "    ds = None\n",
    "    \n",
    "    image = np.moveaxis(image, 0, -1) # expects an image in rows, columns, channels\n",
    "    out_image = []\n",
    "    for i in range(0, image.shape[0], block):\n",
    "        outrow = []\n",
    "        if i >= MAX_SCALE and i <= image.shape[0] - MAX_SCALE:\n",
    "            for j in range(0, image.shape[1], block):\n",
    "                if j >= MAX_SCALE and j <= image.shape[1] - MAX_SCALE:\n",
    "                    block_arr = image[i:i+block,j:j+block]\n",
    "                    center_i = int(i+block/2)\n",
    "                    center_j = int(j+block/2)\n",
    "                    if len(out_image) == 0 and len(outrow) == 0:\n",
    "                        out_uly = uly + cell_height * (center_i - block)\n",
    "                        out_ulx = ulx + cell_width * (center_j - block)\n",
    "                    if block%2 != 0 and scale%2 == 0: # make sure the scale window is the correct size for the block\n",
    "                        scale_arr = image[center_i-int(scale/2):center_i+int(scale/2),center_j-int(scale/2):center_j+int(scale/2)]\n",
    "                    else:\n",
    "                        scale_arr = image[center_i-int(scale/2):center_i+int(scale/2)+1,center_j-int(scale/2):center_j+int(scale/2)+1]      \n",
    "                    fd = hog(scale_arr, orientations=8, pixels_per_cell=(scale_arr.shape[0], scale_arr.shape[1]), cells_per_block=(1, 1), multichannel=True, feature_vector=False)\n",
    "                    outrow.append(fd.flatten())\n",
    "            out_image.append(outrow)\n",
    "    out_arr = np.moveaxis(out_image, -1, 0)\n",
    "    \n",
    "    \"\"\"for i in range(int(scale/2), image.shape[0] - int(scale/2), block):\n",
    "        outrow = []\n",
    "        for j in range(int(scale/2), image.shape[1] - int(scale/2), block):\n",
    "            block_arr = image[i:i+block,j:j+block]\n",
    "            center_i = int(i+block/2)\n",
    "            center_j = int(j+block/2)\n",
    "            if len(out_image) == 0 and len(outrow) == 0:\n",
    "                out_uly = uly + cell_height * (center_i - block)\n",
    "                out_ulx = ulx + cell_width * (center_j - block)\n",
    "            if block%2 != 0 and scale%2 == 0: # make sure the scale window is the correct size for the block\n",
    "                scale_arr = image[center_i-int(scale/2):center_i+int(scale/2),center_j-int(scale/2):center_j+int(scale/2)]\n",
    "            else:\n",
    "                scale_arr = image[center_i-int(scale/2):center_i+int(scale/2)+1,center_j-int(scale/2):center_j+int(scale/2)+1]      \n",
    "            fd = hog(scale_arr, orientations=8, pixels_per_cell=(scale_arr.shape[0], scale_arr.shape[1]), cells_per_block=(1, 1), multichannel=True, feature_vector=False)\n",
    "            outrow.append(fd.flatten())\n",
    "        out_image.append(outrow)\n",
    "    out_arr = np.moveaxis(out_image, -1, 0)\"\"\"\n",
    "    \n",
    "    if output:\n",
    "        if stat:\n",
    "            out_arr = calc_stat(out_arr, \"all\", 0)\n",
    "        out_geotran = (out_ulx, out_cell_width, 0, out_uly, 0, out_cell_height)\n",
    "        # this should be a standardized write geotiff function\n",
    "        write_geotiff(output, out_arr, out_geotran, out_srs_wkt)\n",
    "    else:\n",
    "        return np.array(out_arr)\n",
    "    \n",
    "def glcm_feature(image_name, block, scale, output=None, prop=None, stat=None):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    image_name: str\n",
    "    block: int\n",
    "    scale: int\n",
    "    prop: str\n",
    "    stat: str\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    out_image: 2D or 3D ndarray (depends on the input)\n",
    "    \"\"\"\n",
    "    ds = gdal.Open(image_name)\n",
    "    image = ds.ReadAsArray()\n",
    "    geotran = ds.GetGeoTransform()\n",
    "    ulx = geotran[0]\n",
    "    uly = geotran[3]\n",
    "    cell_width = geotran[1]\n",
    "    cell_height = geotran[5]\n",
    "    \n",
    "    out_srs = osr.SpatialReference()\n",
    "    out_srs.ImportFromEPSG(4326)\n",
    "    out_srs_wkt = out_srs.ExportToWkt()\n",
    "    out_cell_width = block * cell_width\n",
    "    out_cell_height = block * cell_height\n",
    "    \n",
    "    ds = None\n",
    "    image = np.moveaxis(image, 0, -1)\n",
    "    image = skimage.img_as_ubyte(rgb2gray(image))\n",
    "    \n",
    "    pi = 3.14159265\n",
    "    angles = [0., pi/6., pi/4., pi/3., pi/2., (2.*pi)/3., (3.*pi)/4., (5.*pi)/6.]\n",
    "    # dist = [1, 2, 4, 8, 16, 32, 64, 128]\n",
    "    dist = [10, 20]\n",
    "    distances = [n for n in dist if n < scale]\n",
    "    \n",
    "    out_image = []\n",
    "    for i in range(0, image.shape[0], block):\n",
    "        outrow = []\n",
    "        if i >= MAX_SCALE and i <= image.shape[0] - MAX_SCALE:\n",
    "            for j in range(0, image.shape[1], block):\n",
    "                if j >= MAX_SCALE and j <= image.shape[1] - MAX_SCALE:\n",
    "                    block_arr = image[i:i+block,j:j+block]\n",
    "                    center_i = int(i+block/2)\n",
    "                    center_j = int(j+block/2)\n",
    "                    if len(out_image) == 0 and len(outrow) == 0:\n",
    "                        out_uly = uly + cell_height * (center_i - block)\n",
    "                        out_ulx = ulx + cell_width * (center_j - block)\n",
    "                    if block%2 != 0 and scale%2 == 0: # make sure the scale window is the correct size for the block\n",
    "                        scale_arr = image[center_i-int(scale/2):center_i+int(scale/2),center_j-int(scale/2):center_j+int(scale/2)]\n",
    "                    else:\n",
    "                        scale_arr = image[center_i-int(scale/2):center_i+int(scale/2)+1,center_j-int(scale/2):center_j+int(scale/2)+1]      \n",
    "\n",
    "                    out = greycomatrix(scale_arr, distances, angles)\n",
    "                    if prop:\n",
    "                        if prop == \"variance\": # variance is not included in greycoprops, so use a custom implementation\n",
    "                            print('hi')\n",
    "                        else:\n",
    "                            out = greycoprops(out, prop) # results 2d array [d, a] is the property for th d'th distance and a'th angle\n",
    "                            if stat:\n",
    "                                out = calc_stat(out, stat, None)\n",
    "                    else:\n",
    "                        if stat:\n",
    "                            out = calc_stat(out, stat, None)\n",
    "                        else:\n",
    "                            return out\n",
    "                    outrow.append(out)\n",
    "            out_image.append(outrow)\n",
    "    out_image = np.array(out_image)\n",
    "    \"\"\"for i in range(int(scale/2), image.shape[0] - int(scale/2), block):\n",
    "        outrow = []\n",
    "        for j in range(int(scale/2), image.shape[1] - int(scale/2), block):\n",
    "            block_arr = image[i:i+block,j:j+block]\n",
    "            center_i = int(i+block/2)\n",
    "            center_j = int(j+block/2)\n",
    "            if block%2 != 0 and scale%2 == 0: # make sure the scale window is the correct size for the block\n",
    "                scale_arr = image[center_i-int(scale/2):center_i+int(scale/2),center_j-int(scale/2):center_j+int(scale/2)]\n",
    "            else:\n",
    "                scale_arr = image[center_i-int(scale/2):center_i+int(scale/2)+1,center_j-int(scale/2):center_j+int(scale/2)+1]      \n",
    "            \n",
    "            out = greycomatrix(scale_arr, distances, angles)\n",
    "            \n",
    "            if prop:\n",
    "                if prop == \"variance\": # variance is not included in greycoprops\n",
    "                    print('hi')\n",
    "                else:\n",
    "                    out = greycoprops(out, prop) # results 2d array [d, a] is the property for th d'th distance and a'th angle\n",
    "                    if stat:\n",
    "                        out = calc_stat(out, stat, None)\n",
    "            else:\n",
    "                if stat:\n",
    "                    out = calc_stat(out, stat, None)\n",
    "                else:\n",
    "                    return out\n",
    "            outrow.append(out)\n",
    "        out_image.append(outrow)\"\"\"\n",
    "   \n",
    "    if output:\n",
    "        out_geotran = (out_ulx, out_cell_width, 0, out_uly, 0, out_cell_height)\n",
    "        # this should be a standardized write geotiff function\n",
    "        write_geotiff(output, out_image, out_geotran, out_srs_wkt)\n",
    "    else:\n",
    "        return np.array(out_image)\n",
    "\n",
    "    \n",
    "def pantex_feature(image_name, block, scale, output=None):\n",
    "    if output:\n",
    "        glcm_feature(image_name, block, scale, output=output, prop=\"contrast\", stat=\"min\")\n",
    "    else:\n",
    "        return glcm_feature(image_name, block, scale, prop=\"contrast\", stat=\"min\")\n",
    "\n",
    "def get_se_set(sizes):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    sizes: list\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    se_set: ndarray (4D)\n",
    "        se_set[0] gives the linear directional kernels for size\n",
    "            at index zero\n",
    "        se_set[1] gives the linear direction kernels for size at\n",
    "            index 1\n",
    "    \"\"\"\n",
    "    se_set = []\n",
    "    for se_size in sizes:\n",
    "        assert(se_size%2!=0)\n",
    "        # create a structural element for the direction and size\n",
    "        # directions are hardcoded to 4 for now. it generates 4\n",
    "        # kernels with directions of 0, 45, 90, and 135\n",
    "        se0 = np.zeros(shape=(se_size,se_size))\n",
    "        se0[se_size//2,:] = 1\n",
    "        se45 = np.diagflat(np.ones(shape=(se_size)))[::-1]\n",
    "        se90 = np.zeros(shape=(se_size,se_size))\n",
    "        se90[:,se_size//2] = 1\n",
    "        se135 = np.diagflat(np.ones(shape=(se_size)))\n",
    "        se_set.append([se0, se45, se90, se135])\n",
    "    return se_set\n",
    "\n",
    "def MBI_feature(image_name, postprocess=True):\n",
    "    MBI_THRESHOLD = 5.5\n",
    "    \n",
    "    ds = gdal.Open(image_name)\n",
    "    image = ds.ReadAsArray()\n",
    "    ds = None\n",
    "    image = np.moveaxis(image, 0, -1) # rows, columns, channels\n",
    "    # calculate brightness as a local max\n",
    "    brightness = calc_stat(image, \"max\", 2)\n",
    "    # a set of linear structural elements\n",
    "    # for the white tophat transformation\n",
    "    # dirs = [45, 90, 135, 180]\n",
    "    se_sizes = [5, 9, 13, 19, 23, 27]\n",
    "    se_set = get_se_set(se_sizes)\n",
    "    # 'white' top-hat transformation\n",
    "    # in this case, white top-hat is the brightness image minus morphological opening\n",
    "    mean_w_tophats = []\n",
    "    for s in se_set: # for each size in the structural element set\n",
    "        w_tophats = []\n",
    "        for k in s: # for each direction kernel in the structural element set for this size\n",
    "            # directional top hat transformation using linear SE\n",
    "            w_tophats.append(white_tophat(brightness, k))\n",
    "        mean_w_tophat = calc_stat(w_tophats, 'mean', 0)\n",
    "        mean_w_tophats.append(mean_w_tophat)\n",
    "    \n",
    "    th_dmp = []\n",
    "    th_idx = 0\n",
    "    while th_idx + 1 < len(mean_w_tophats):\n",
    "        th_dmp.append(np.absolute(mean_w_tophats[th_idx + 1] - mean_w_tophats[th_idx]))\n",
    "        th_idx+=1\n",
    "    mbi = calc_stat(np.array(th_dmp), 'mean', 0)\n",
    "    if postprocess:\n",
    "        mbi = np.where(mbi >= MBI_THRESHOLD, 1, 0)\n",
    "    return mbi\n",
    "\n",
    "def LSR_feature(dat_directory):\n",
    "    files = os.listdir(dat_directory)\n",
    "    for f in files:\n",
    "        infile = open(os.path.join(dat_directory, f))\n",
    "        line = infile.readline()\n",
    "        while line != \"\":\n",
    "            line = line.strip().split(\",\")\n",
    "            llen = line[0] # line length\n",
    "            lmx = line[1] # middle x coordinate\n",
    "            lmy = line[2] # middle y coordinate\n",
    "            lorn = line[3] # line orientation\n",
    "            \n",
    "\n",
    "def textons_feature(image_name, block, scale):\n",
    "    return NotImplemented\n",
    "        \n",
    "    \n",
    "def calc_stat(arr, stat_name, axis=None):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    arr: ndarray\n",
    "        the input array\n",
    "    stat_name: str\n",
    "        the name of the statistics.\n",
    "        \"max\", \"min\", \"mean\", \"var\", \"std\"\n",
    "    axis: int, optional\n",
    "        the axis over which the statistics is calculated\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    out: ndarray\n",
    "    \"\"\"\n",
    "    if stat_name == \"all\":\n",
    "        out = np.array([np.amin(arr, axis), np.amax(arr, axis), np.mean(arr, axis), np.var(arr, axis), np.sum(arr, axis)])\n",
    "    elif stat_name == \"min\":\n",
    "        out = np.amin(arr, axis)\n",
    "    elif stat_name == \"max\":\n",
    "        out = np.amax(arr, axis)\n",
    "    elif stat_name == \"var\":\n",
    "        out = np.var(arr, axis)\n",
    "    elif stat_name == \"mean\":\n",
    "        out = np.mean(arr, axis)\n",
    "    elif stat_name == \"std\":\n",
    "        out = np.std(arr, axis)\n",
    "    else: # stat_name == \"sum\":\n",
    "        out = np.sum(arr, axis)\n",
    "    return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
